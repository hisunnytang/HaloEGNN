{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HaloEGNN_Train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1EMCV8e9HtlVrw70EZjQCKZFjNuXSpikI",
      "authorship_tag": "ABX9TyPatq04ExpeGZN0i4jTg1Uo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hisunnytang/HaloEGNN/blob/main/notebooks/HaloEGNN_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "88CEO2Jn13OW"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install torchdiffeq\n",
        "!pip install gdown\n",
        "!git clone https://github.com/hisunnytang/HaloEGNN.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e HaloEGNN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MFpTpAUsjCj",
        "outputId": "d14bb635-15dc-405e-e941-ce5a7611bc79"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/HaloEGNN\n",
            "Installing collected packages: HaloFlows\n",
            "  Running setup.py develop for HaloFlows\n",
            "Successfully installed HaloFlows-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check the resources allocated"
      ],
      "metadata": {
        "id": "GExefu5B6ee_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77Xvx5A-6hWs",
        "outputId": "7f3bbe0e-1a49-411f-ac03-e7c703d83603"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Apr  3 21:07:13 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lscpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2xCUI2p6jK0",
        "outputId": "1eeb8573-add3-4882-f7db-2610f5cb06cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              4\n",
            "On-line CPU(s) list: 0-3\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  2\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               63\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2299.998\n",
            "BogoMIPS:            4599.99\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            46080K\n",
            "NUMA node0 CPU(s):   0-3\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/HaloEGNN_sample_data/subhalo_columns.npy .\n",
        "!cp /content/drive/MyDrive/HaloEGNN_sample_data/preprocessed_data.zip ."
      ],
      "metadata": {
        "id": "PC5_iUzlqjOi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cannot directly use the cli for now, but you can still download this, and upload it back to colab\n",
        "#!gdown https://drive.google.com/uc?id=1hpaQjfSi_TfdbmCEKf2PeSkDAlBX3jBV "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lPt_IRc61qJ",
        "outputId": "cf3cd78b-6de5-413d-98cd-e577c02597f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1hpaQjfSi_TfdbmCEKf2PeSkDAlBX3jBV \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip preprocessed_data.zip"
      ],
      "metadata": {
        "id": "Dif-HtyV7k8n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Restart here for the system to see the package"
      ],
      "metadata": {
        "id": "MvVsxSSn44ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from HaloEGNNFlows.train import *"
      ],
      "metadata": {
        "id": "ryuLKdXNxUwB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import torch\n",
        "# import glob\n",
        "# import pandas as pd\n",
        "# import ipywidgets as widgets\n",
        "# import seaborn as sns\n",
        "# import pickle\n",
        "# from HaloEGNNFlows.EGNNFlows.models import get_model\n",
        "# from HaloEGNNFlows.EGNNFlows.datasets import \\\n",
        "# (\n",
        "#  ProgenitorDataset,\n",
        "#  find_closest_redshift_slice, \n",
        "#  prepare_input_data\n",
        "#  )\n",
        "\n",
        "# from HaloEGNNFlows.EGNNFlows.viz.utils import compute_metric_features\n",
        "# from HaloEGNNFlows.EGNNFlows.flows.utils import assert_correctly_masked\n",
        "# from HaloEGNNFlows.EGNNFlows.flow_forward import  flow_forward\n",
        "# import re\n",
        "# from collections import OrderedDict"
      ],
      "metadata": {
        "id": "RjZYdmkm224S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from HaloEGNN.train import train_loop, prepare_filelist_and_transformer, get_model"
      ],
      "metadata": {
        "id": "RfuAuewu3LzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm TNG300_preprocessed_data/prog_sublink_1849472.npy"
      ],
      "metadata": {
        "id": "IlYP7I-WfGHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_loc = 'TNG300_preprocessed_data'\n",
        "# Prepare file list\n",
        "filelist = sorted(glob.glob(f\"{preprocessed_loc}/prog_sublink_*.npy\"))\n",
        "# Prepare the columns names\n",
        "full_columns_names = np.load(f\"{preprocessed_loc}/subhalo_columns.npy\")\n",
        "\n",
        "# The \"scalar\" feature bounded to the progenitors\n",
        "feature_columns = [\"SubhaloMass\", \"SubhaloMergeRedshift\"]\n",
        "# The \"positional\" feature bounded to the progenitors\n",
        "position_columns = [\"SubhaloPos_0\", \"SubhaloPos_1\", \"SubhaloPos_2\"]\n",
        "\n",
        "# initialize the list condtional columns at redshift 0\n",
        "condition_columns = [\n",
        "    \"SubhaloBHMass\",\n",
        "    \"SubhaloBHMdot\",\n",
        "    \"SubhaloGasMetallicity\",\n",
        "    \"SubhaloStarMetallicity\",\n",
        "    \"SubhaloMass\",\n",
        "    \"DMFrac\",\n",
        "    \"GasFrac\",\n",
        "    \"StarWindFrac\",\n",
        "    \"BHFrac\",\n",
        "    \"SubhaloSFR\",\n",
        "    \"SubhaloVmax\",\n",
        "    \"SubhaloVelDisp\",\n",
        "]"
      ],
      "metadata": {
        "id": "7KSIDuzT4FUo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "failed = []\n",
        "for f in filelist:\n",
        "  try:\n",
        "    np.load(f)\n",
        "  except:\n",
        "    print(f)\n",
        "    failed.append(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz5zIR6PdfHF",
        "outputId": "af343af6-61a0-4372-e3e9-79cda39f9e4a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TNG300_preprocessed_data/prog_sublink_1849472.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_files, condition_normalizer = prepare_filelist_and_transformer(\n",
        "    filelist_npy=None,\n",
        "    transformer_pkl=None,\n",
        "    filelist=filelist,\n",
        "    condition_columns=condition_columns,\n",
        "    full_columns_names=full_columns_names,\n",
        "    max_progenitors=20,\n",
        "    initial_slice=0,\n",
        "    final_slice=1,\n",
        "    batch_size=512,\n",
        "    num_workers=4,\n",
        "    transform_type = \"quantile\"\n",
        ")"
      ],
      "metadata": {
        "id": "RqZi0uMg43JZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PBS_JOBID\"] = '040322'"
      ],
      "metadata": {
        "id": "nK3G6N9m8Uyb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 1000\n",
        "ode_reg    = 0.01\n",
        "\n",
        "train_loop(\n",
        "    valid_files,\n",
        "    max_epochs,\n",
        "    condition_normalizer,\n",
        "    ode_reg,\n",
        "    # The \"scalar\" feature bounded to the progenitors\n",
        "    feature_columns,\n",
        "    # The \"positional\" feature bounded to the progenitors\n",
        "    position_columns,\n",
        "    # initialize the list condtional columns at redshift 0\n",
        "    condition_columns,\n",
        "    full_columns_names,\n",
        "    restart_path=None,\n",
        "    batch_size=512,\n",
        "    lr=1e-3,\n",
        "    patience=3,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXl0IXza7b9x",
        "outputId": "3e4ade24-1c87-4c8d-e9f3-1d586aeb720e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/119 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initializing actnorm layer on device = cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [36:14<00:00, 18.27s/it, train_loss=104, nll=103]\n",
            "100%|██████████| 15/15 [01:25<00:00,  5.70s/it, val_loss=92.6, nll=91.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint: log_dir/040322/egnn_0_val=92.603.pt\n",
            "Epoch 0: train loss = 103.70; val loss = 92.60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [38:22<00:00, 19.35s/it, train_loss=89.3, nll=87.9]\n",
            "100%|██████████| 15/15 [01:45<00:00,  7.05s/it, val_loss=90.4, nll=89]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint: log_dir/040322/egnn_1_val=90.398.pt\n",
            "Epoch 1: train loss = 89.29; val loss = 90.40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 33/119 [14:27<33:44, 23.54s/it, train_loss=87.9, nll=86.5]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_path = \"egnn_16_val=74.837.pt\""
      ],
      "metadata": {
        "id": "_J2X1hRWy25s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the checkpoint path\n",
        "ckpt = torch.load(ckpt_path)\n",
        "\n",
        "n_dims = len(position_columns)\n",
        "in_node_nf = len(feature_columns)\n",
        "context_node_nf = len(condition_columns)\n",
        "\n",
        "valid_files, condition_normalizer = prepare_filelist_and_transformer(\n",
        "    filelist_npy=None,\n",
        "    transformer_pkl=None,\n",
        "    filelist=filelist,\n",
        "    condition_columns=condition_columns,\n",
        "    full_columns_names=full_columns_names,\n",
        "    max_progenitors=20,\n",
        "    initial_slice=0,\n",
        "    final_slice=1,\n",
        "    batch_size=512,\n",
        "    num_workers=4,\n",
        "    transform_type = \"quantile\"\n",
        ")\n",
        "\n",
        "# TODO: hyperparameters should also be stored in the ckpt\n",
        "# INITIALIZE the model\n",
        "# Prepare Models and Priors/ Optimizer/ LR scheduler\n",
        "prior, flow = get_model(\n",
        "    in_node_nf=in_node_nf,  # Number of Features to fit (i.e. Progenitor Halo Mass)\n",
        "    dynamics_in_node_nf=1,  # Use Time as additional Feature\n",
        "    context_node_nf=context_node_nf,  # Number of Conditional Features\n",
        "    n_dims=n_dims,  # Number of \"Equivariant\" Dimension\n",
        ")\n",
        "optim = torch.optim.AdamW(flow.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optim, verbose=1, mode=\"min\", min_lr=1e-8, patience=3\n",
        ")\n",
        "ode_regularization = 0.01\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "Ojr9Nd5I8M85"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load state dict from last epoch\n",
        "current_epoch = ckpt[\"epoch\"]\n",
        "flow.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "optim.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
        "scheduler.load_state_dict(ckpt[\"scheduler_state_dict\"])\n",
        "# train_history\n",
        "train_loss = ckpt[\"loss\"]\n",
        "val_loss = ckpt[\"val_loss\"]\n",
        "max_epochs = len(train_loss)"
      ],
      "metadata": {
        "id": "YP-eCY-nzyvi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dirname = os.path.dirname(ckpt_path)\n",
        "# condition_normalizer = pickle.load(open(os.path.join(dirname, \"scaler.pkl\"), \"rb\"))\n",
        "log_path = create_log_directory(\"log_dir\")"
      ],
      "metadata": {
        "id": "fxnV-LnnzjtS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare dataloaders\n",
        "dl_train, dl_val, dl_test = prepare_dataloaders(\n",
        "    valid_files,\n",
        "    condition_columns,\n",
        "    full_columns_names,\n",
        "    max_progenitors=20,\n",
        "    initial_slice=0,\n",
        "    final_slice=1,\n",
        "    batch_size=512,\n",
        "    num_workers=4,\n",
        "    random_seed=42,\n",
        "    train_test_split=[0.8, 0.1, 0.1],\n",
        "    shuffle_train=True,\n",
        "    distributed=False,\n",
        ")"
      ],
      "metadata": {
        "id": "YIu1MhF3lmsB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zidx = None"
      ],
      "metadata": {
        "id": "1kng8xVUzoLw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(current_epoch, max_epochs):\n",
        "  loss = train_step(\n",
        "      flow,\n",
        "      prior,\n",
        "      optim,\n",
        "      dl_train,\n",
        "      condition_normalizer,\n",
        "      device=device,\n",
        "      ode_regularization=ode_regularization,\n",
        "      transform_input=transform_z_to_scale(zidx),\n",
        "  )\n",
        "  val = val_step(\n",
        "      flow,\n",
        "      prior,\n",
        "      dl_val,\n",
        "      condition_normalizer,\n",
        "      device=device,\n",
        "      ode_regularization=ode_regularization,\n",
        "      transform_input=transform_z_to_scale(zidx),\n",
        "  )\n",
        "\n",
        "  print(f\"Epoch {i}: train loss = {loss.item():.2f}; val loss = {val.item():.2f}\")\n",
        "  train_loss[i] = loss\n",
        "  val_loss[i] = val\n",
        "  scheduler.step(val)\n",
        "  checkpoint_model(\n",
        "      flow, scheduler, optim, train_loss, val_loss, epoch=i, log_path=log_path\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bYnpY0fzZZv",
        "outputId": "ceccf429-a4e2-4ced-f54f-bd82863e6193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [1:08:24<00:00, 34.49s/it, train_loss=74.8, nll=73]\n",
            "100%|██████████| 15/15 [03:01<00:00, 12.07s/it, val_loss=74.9, nll=73]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: train loss = 74.78; val loss = 74.89\n",
            "Checkpoint: log_dir/033022/egnn_16_val=74.894.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [1:06:32<00:00, 33.55s/it, train_loss=74.6, nll=72.8]\n",
            "100%|██████████| 15/15 [02:36<00:00, 10.43s/it, val_loss=75, nll=73.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: train loss = 74.64; val loss = 74.97\n",
            "Checkpoint: log_dir/033022/egnn_17_val=74.971.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [1:05:09<00:00, 32.85s/it, train_loss=74.4, nll=72.5]\n",
            "100%|██████████| 15/15 [03:00<00:00, 12.04s/it, val_loss=74, nll=72]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: train loss = 74.35; val loss = 73.99\n",
            "Checkpoint: log_dir/033022/egnn_18_val=73.993.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [1:11:48<00:00, 36.20s/it, train_loss=73.9, nll=72]\n",
            "100%|██████████| 15/15 [02:54<00:00, 11.66s/it, val_loss=74, nll=72.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: train loss = 73.91; val loss = 74.03\n",
            "Checkpoint: log_dir/033022/egnn_19_val=74.029.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [1:09:35<00:00, 35.09s/it, train_loss=73.5, nll=71.6]\n",
            "100%|██████████| 15/15 [02:30<00:00, 10.04s/it, val_loss=74.6, nll=72.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: train loss = 73.54; val loss = 74.62\n",
            "Checkpoint: log_dir/033022/egnn_20_val=74.624.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [1:08:59<00:00, 34.79s/it, train_loss=73.6, nll=71.6]\n",
            "100%|██████████| 15/15 [02:40<00:00, 10.71s/it, val_loss=73.1, nll=71]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: train loss = 73.57; val loss = 73.07\n",
            "Checkpoint: log_dir/033022/egnn_21_val=73.073.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [1:10:47<00:00, 35.69s/it, train_loss=73.4, nll=71.4]\n",
            "100%|██████████| 15/15 [02:32<00:00, 10.16s/it, val_loss=74.2, nll=72.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: train loss = 73.36; val loss = 74.23\n",
            "Checkpoint: log_dir/033022/egnn_22_val=74.233.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [1:10:14<00:00, 35.41s/it, train_loss=73.3, nll=71.3]\n",
            "100%|██████████| 15/15 [02:44<00:00, 10.97s/it, val_loss=73.5, nll=71.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: train loss = 73.31; val loss = 73.47\n",
            "Checkpoint: log_dir/033022/egnn_23_val=73.470.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [1:14:33<00:00, 37.59s/it, train_loss=72.9, nll=70.9]\n",
            "100%|██████████| 15/15 [03:07<00:00, 12.52s/it, val_loss=73.4, nll=71.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: train loss = 72.92; val loss = 73.41\n",
            "Checkpoint: log_dir/033022/egnn_24_val=73.409.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [1:16:11<00:00, 38.41s/it, train_loss=72.9, nll=70.9]\n",
            "100%|██████████| 15/15 [02:40<00:00, 10.71s/it, val_loss=72.9, nll=70.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: train loss = 72.92; val loss = 72.88\n",
            "Checkpoint: log_dir/033022/egnn_25_val=72.875.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [1:13:49<00:00, 37.22s/it, train_loss=72.6, nll=70.5]\n",
            "100%|██████████| 15/15 [03:12<00:00, 12.84s/it, val_loss=71.7, nll=69.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26: train loss = 72.56; val loss = 71.74\n",
            "Checkpoint: log_dir/033022/egnn_26_val=71.737.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [1:17:10<00:00, 38.91s/it, train_loss=72.3, nll=70.2]\n",
            "100%|██████████| 15/15 [02:44<00:00, 10.98s/it, val_loss=72.8, nll=70.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27: train loss = 72.27; val loss = 72.85\n",
            "Checkpoint: log_dir/033022/egnn_27_val=72.848.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119/119 [1:16:47<00:00, 38.72s/it, train_loss=72.1, nll=70]\n",
            "100%|██████████| 15/15 [03:00<00:00, 12.04s/it, val_loss=72.7, nll=70.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28: train loss = 72.09; val loss = 72.70\n",
            "Checkpoint: log_dir/033022/egnn_28_val=72.696.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 87/119 [57:20<21:33, 40.41s/it, train_loss=72.1, nll=70]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1FafBRZfzrPj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}